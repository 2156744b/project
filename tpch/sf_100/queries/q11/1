15/09/06 02:39:10 INFO metastore: Trying to connect to metastore with URI thrift://sandbox.hortonworks.com:9083
15/09/06 02:39:10 INFO metastore: Connected to metastore.
15/09/06 02:39:11 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/09/06 02:39:11 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:11 INFO SparkContext: Running Spark version 1.4.1
15/09/06 02:39:11 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:11 INFO SecurityManager: Changing view acls to: hive
15/09/06 02:39:11 INFO SecurityManager: Changing modify acls to: hive
15/09/06 02:39:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hive); users with modify permissions: Set(hive)
15/09/06 02:39:12 INFO Slf4jLogger: Slf4jLogger started
15/09/06 02:39:12 INFO Remoting: Starting remoting
15/09/06 02:39:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.122.56:53190]
15/09/06 02:39:12 INFO Utils: Successfully started service 'sparkDriver' on port 53190.
15/09/06 02:39:12 INFO SparkEnv: Registering MapOutputTracker
15/09/06 02:39:12 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:12 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:12 INFO SparkEnv: Registering BlockManagerMaster
15/09/06 02:39:12 INFO DiskBlockManager: Created local directory at /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a
15/09/06 02:39:12 INFO MemoryStore: MemoryStore started with capacity 20.7 GB
15/09/06 02:39:12 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/httpd-b2cd09a8-44b6-4ec8-8f57-99584e589578
15/09/06 02:39:12 INFO HttpServer: Starting HTTP Server
15/09/06 02:39:12 INFO Server: jetty-8.y.z-SNAPSHOT
15/09/06 02:39:12 INFO AbstractConnector: Started SocketConnector@0.0.0.0:39284
15/09/06 02:39:12 INFO Utils: Successfully started service 'HTTP file server' on port 39284.
15/09/06 02:39:12 INFO SparkEnv: Registering OutputCommitCoordinator
15/09/06 02:39:13 INFO Server: jetty-8.y.z-SNAPSHOT
15/09/06 02:39:13 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/09/06 02:39:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/09/06 02:39:13 INFO SparkUI: Started SparkUI at http://192.168.122.56:4040
15/09/06 02:39:13 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:13 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:13 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:13 INFO Executor: Starting executor ID driver on host localhost
15/09/06 02:39:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41393.
15/09/06 02:39:13 INFO NettyBlockTransferService: Server created on 41393
15/09/06 02:39:13 INFO BlockManagerMaster: Trying to register BlockManager
15/09/06 02:39:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41393 with 20.7 GB RAM, BlockManagerId(driver, localhost, 41393)
15/09/06 02:39:13 INFO BlockManagerMaster: Registered BlockManager
15/09/06 02:39:13 INFO EventLoggingListener: Logging events to file:/tmp/spark-events/local-1441507153302
15/09/06 02:39:14 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/09/06 02:39:14 INFO HiveContext: Initializing execution hive, version 0.13.1
15/09/06 02:39:14 INFO HiveContext: Initializing HiveMetastoreConnection version 0.13.1 using Spark classes.
15/09/06 02:39:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/09/06 02:39:15 INFO metastore: Trying to connect to metastore with URI thrift://sandbox.hortonworks.com:9083
15/09/06 02:39:15 INFO metastore: Connected to metastore.
15/09/06 02:39:16 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
15/09/06 02:39:16 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/09/06 02:39:16 INFO ParseDriver: Parsing command: -- the query
insert overwrite table q11_part_tmp_par
select
  ps_partkey,
  sum(ps_supplycost * ps_availqty) as part_value
from
  nation_par n join supplier_par s on s.s_nationkey = n.n_nationkey and n.n_name = 'RUSSIA'
  join partsupp_par ps on ps.ps_suppkey = s.s_suppkey
group by
    ps_partkey
15/09/06 02:39:17 INFO ParseDriver: Parse Completed
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
15/09/06 02:39:20 INFO MemoryStore: ensureFreeSpace(326528) called with curMem=0, maxMem=22226833244
15/09/06 02:39:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 318.9 KB, free 20.7 GB)
15/09/06 02:39:20 INFO MemoryStore: ensureFreeSpace(22794) called with curMem=326528, maxMem=22226833244
15/09/06 02:39:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 20.7 GB)
15/09/06 02:39:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41393 (size: 22.3 KB, free: 20.7 GB)
15/09/06 02:39:20 INFO SparkContext: Created broadcast 0 from processCmd at CliDriver.java:423
15/09/06 02:39:20 INFO MemoryStore: ensureFreeSpace(326584) called with curMem=349322, maxMem=22226833244
15/09/06 02:39:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 318.9 KB, free 20.7 GB)
15/09/06 02:39:20 INFO MemoryStore: ensureFreeSpace(22794) called with curMem=675906, maxMem=22226833244
15/09/06 02:39:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.3 KB, free 20.7 GB)
15/09/06 02:39:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41393 (size: 22.3 KB, free: 20.7 GB)
15/09/06 02:39:20 INFO SparkContext: Created broadcast 1 from processCmd at CliDriver.java:423
15/09/06 02:39:20 INFO MemoryStore: ensureFreeSpace(326584) called with curMem=698700, maxMem=22226833244
15/09/06 02:39:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 318.9 KB, free 20.7 GB)
15/09/06 02:39:20 INFO MemoryStore: ensureFreeSpace(22794) called with curMem=1025284, maxMem=22226833244
15/09/06 02:39:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 22.3 KB, free 20.7 GB)
15/09/06 02:39:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41393 (size: 22.3 KB, free: 20.7 GB)
15/09/06 02:39:20 INFO deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
15/09/06 02:39:20 INFO deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
15/09/06 02:39:20 INFO SparkContext: Created broadcast 2 from processCmd at CliDriver.java:423
15/09/06 02:39:20 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1$$anon$2: Using Task Side Metadata Split Strategy
15/09/06 02:39:20 INFO Exchange: Using SparkSqlSerializer2.
15/09/06 02:39:20 INFO Exchange: Using SparkSqlSerializer2.
15/09/06 02:39:21 INFO SparkContext: Starting job: run at ThreadPoolExecutor.java:1145
15/09/06 02:39:21 INFO Exchange: Using SparkSqlSerializer2.
15/09/06 02:39:21 INFO DAGScheduler: Got job 0 (run at ThreadPoolExecutor.java:1145) with 1 output partitions (allowLocal=false)
15/09/06 02:39:21 INFO DAGScheduler: Final stage: ResultStage 0(run at ThreadPoolExecutor.java:1145)
15/09/06 02:39:21 INFO DAGScheduler: Parents of final stage: List()
15/09/06 02:39:21 INFO DAGScheduler: Missing parents: List()
15/09/06 02:39:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at run at ThreadPoolExecutor.java:1145), which has no missing parents
15/09/06 02:39:21 INFO MemoryStore: ensureFreeSpace(6144) called with curMem=1048078, maxMem=22226833244
15/09/06 02:39:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.0 KB, free 20.7 GB)
15/09/06 02:39:21 INFO MemoryStore: ensureFreeSpace(3283) called with curMem=1054222, maxMem=22226833244
15/09/06 02:39:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.2 KB, free 20.7 GB)
15/09/06 02:39:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:41393 (size: 3.2 KB, free: 20.7 GB)
15/09/06 02:39:21 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:874
15/09/06 02:39:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at run at ThreadPoolExecutor.java:1145)
15/09/06 02:39:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
15/09/06 02:39:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, ANY, 1682 bytes)
15/09/06 02:39:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/09/06 02:39:21 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/nation_par/000000_0 start: 0 end: 2330 length: 2330 hosts: [] requestedSchema: message root {
  optional int32 n_nationkey;
  optional binary n_name (UTF8);
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"n_nationkey","type":"integer","nullable":true,"metadata":{}},{"name":"n_name","type":"string","nullable":true,"metadata":{}},{"name":"n_regionkey","type":"integer","nullable":true,"metadata":{}},{"name":"n_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"n_nationkey","type":"integer","nullable":true,"metadata":{}},{"name":"n_name","type":"string","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:21 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1856 bytes result sent to driver
15/09/06 02:39:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 399 ms on localhost (1/1)
15/09/06 02:39:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/09/06 02:39:21 INFO DAGScheduler: ResultStage 0 (run at ThreadPoolExecutor.java:1145) finished in 0.422 s
15/09/06 02:39:21 INFO DAGScheduler: Job 0 finished: run at ThreadPoolExecutor.java:1145, took 0.555602 s
15/09/06 02:39:21 INFO MemoryStore: ensureFreeSpace(344) called with curMem=1057505, maxMem=22226833244
15/09/06 02:39:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 344.0 B, free 20.7 GB)
15/09/06 02:39:21 INFO MemoryStore: ensureFreeSpace(176) called with curMem=1057849, maxMem=22226833244
15/09/06 02:39:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 176.0 B, free 20.7 GB)
15/09/06 02:39:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:41393 (size: 176.0 B, free: 20.7 GB)
15/09/06 02:39:21 INFO SparkContext: Created broadcast 4 from run at ThreadPoolExecutor.java:1145
15/09/06 02:39:21 INFO StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@23e966bb
15/09/06 02:39:21 INFO StatsReportListener: task runtime:(count: 1, mean: 399.000000, stdev: 0.000000, max: 399.000000, min: 399.000000)
15/09/06 02:39:21 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:21 INFO StatsReportListener: 	399.0 ms	399.0 ms	399.0 ms	399.0 ms	399.0 ms	399.0 ms	399.0 ms	399.0 ms	399.0 ms
15/09/06 02:39:21 INFO StatsReportListener: task result size:(count: 1, mean: 1856.000000, stdev: 0.000000, max: 1856.000000, min: 1856.000000)
15/09/06 02:39:21 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:21 INFO StatsReportListener: 	1856.0 B	1856.0 B	1856.0 B	1856.0 B	1856.0 B	1856.0 B	1856.0 B	1856.0 B	1856.0 B
15/09/06 02:39:21 INFO StatsReportListener: executor (non-fetch) time pct: (count: 1, mean: 69.924812, stdev: 0.000000, max: 69.924812, min: 69.924812)
15/09/06 02:39:21 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:21 INFO StatsReportListener: 	70 %	70 %	70 %	70 %	70 %	70 %	70 %	70 %	70 %
15/09/06 02:39:21 INFO StatsReportListener: other time pct: (count: 1, mean: 30.075188, stdev: 0.000000, max: 30.075188, min: 30.075188)
15/09/06 02:39:21 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:21 INFO StatsReportListener: 	30 %	30 %	30 %	30 %	30 %	30 %	30 %	30 %	30 %
15/09/06 02:39:21 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/09/06 02:39:21 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/09/06 02:39:21 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/09/06 02:39:21 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/09/06 02:39:21 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/09/06 02:39:21 INFO ParquetRelation2: Using default output committer for Parquet: parquet.hadoop.ParquetOutputCommitter
15/09/06 02:39:21 INFO DefaultWriterContainer: Using user defined output committer class parquet.hadoop.ParquetOutputCommitter
15/09/06 02:39:21 INFO SparkContext: Starting job: processCmd at CliDriver.java:423
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1$$anon$2: Using Task Side Metadata Split Strategy
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1$$anon$2: Using Task Side Metadata Split Strategy
15/09/06 02:39:22 INFO DAGScheduler: Registering RDD 9 (processCmd at CliDriver.java:423)
15/09/06 02:39:22 INFO DAGScheduler: Registering RDD 14 (processCmd at CliDriver.java:423)
15/09/06 02:39:22 INFO DAGScheduler: Registering RDD 20 (processCmd at CliDriver.java:423)
15/09/06 02:39:22 INFO DAGScheduler: Got job 1 (processCmd at CliDriver.java:423) with 200 output partitions (allowLocal=false)
15/09/06 02:39:22 INFO DAGScheduler: Final stage: ResultStage 4(processCmd at CliDriver.java:423)
15/09/06 02:39:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
15/09/06 02:39:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
15/09/06 02:39:22 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at processCmd at CliDriver.java:423), which has no missing parents
15/09/06 02:39:22 INFO MemoryStore: ensureFreeSpace(6536) called with curMem=1058025, maxMem=22226833244
15/09/06 02:39:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 6.4 KB, free 20.7 GB)
15/09/06 02:39:22 INFO MemoryStore: ensureFreeSpace(3554) called with curMem=1064561, maxMem=22226833244
15/09/06 02:39:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KB, free 20.7 GB)
15/09/06 02:39:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:41393 (size: 3.5 KB, free: 20.7 GB)
15/09/06 02:39:22 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:874
15/09/06 02:39:22 INFO DAGScheduler: Submitting 39 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at processCmd at CliDriver.java:423)
15/09/06 02:39:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 39 tasks
15/09/06 02:39:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, ANY, 1694 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, ANY, 1699 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, ANY, 1708 bytes)
15/09/06 02:39:22 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at processCmd at CliDriver.java:423), which has no missing parents
15/09/06 02:39:22 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, ANY, 1694 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, localhost, ANY, 1699 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6, localhost, ANY, 1707 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7, localhost, ANY, 1693 bytes)
15/09/06 02:39:22 INFO MemoryStore: ensureFreeSpace(9520) called with curMem=1068115, maxMem=22226833244
15/09/06 02:39:22 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8, localhost, ANY, 1699 bytes)
15/09/06 02:39:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 9.3 KB, free 20.7 GB)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9, localhost, ANY, 1709 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10, localhost, ANY, 1693 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11, localhost, ANY, 1699 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 12, localhost, ANY, 1708 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 13, localhost, ANY, 1694 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 14, localhost, ANY, 1699 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 15, localhost, ANY, 1707 bytes)
15/09/06 02:39:22 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 16, localhost, ANY, 1694 bytes)
15/09/06 02:39:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
15/09/06 02:39:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
15/09/06 02:39:22 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
15/09/06 02:39:22 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
15/09/06 02:39:22 INFO MemoryStore: ensureFreeSpace(4935) called with curMem=1077635, maxMem=22226833244
15/09/06 02:39:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.8 KB, free 20.7 GB)
15/09/06 02:39:22 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
15/09/06 02:39:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:41393 (size: 4.8 KB, free: 20.7 GB)
15/09/06 02:39:22 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)
15/09/06 02:39:22 INFO Executor: Running task 8.0 in stage 1.0 (TID 9)
15/09/06 02:39:22 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:874
15/09/06 02:39:22 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)
15/09/06 02:39:22 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at processCmd at CliDriver.java:423)
15/09/06 02:39:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks
15/09/06 02:39:22 INFO Executor: Running task 9.0 in stage 1.0 (TID 10)
15/09/06 02:39:22 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)
15/09/06 02:39:22 INFO Executor: Running task 10.0 in stage 1.0 (TID 11)
15/09/06 02:39:22 INFO Executor: Running task 12.0 in stage 1.0 (TID 13)
15/09/06 02:39:22 INFO Executor: Running task 11.0 in stage 1.0 (TID 12)
15/09/06 02:39:22 INFO Executor: Running task 13.0 in stage 1.0 (TID 14)
15/09/06 02:39:22 INFO Executor: Running task 14.0 in stage 1.0 (TID 15)
15/09/06 02:39:22 INFO Executor: Running task 15.0 in stage 1.0 (TID 16)
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000009_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000005_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000010_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000005_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000009_0 start: 268435456 end: 334658433 length: 66222977 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000010_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000003_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000005_0 start: 268435456 end: 336837881 length: 68402425 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000009_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000003_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000010_0 start: 268435456 end: 334660800 length: 66225344 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000003_0 start: 268435456 end: 336808364 length: 68372908 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000004_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000006_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000006_0 start: 268435456 end: 335698071 length: 67262615 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:22 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000006_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:23 INFO CodecPool: Got brand-new decompressor [.snappy]
15/09/06 02:39:29 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2180 bytes result sent to driver
15/09/06 02:39:29 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 17, localhost, ANY, 1699 bytes)
15/09/06 02:39:29 INFO Executor: Running task 16.0 in stage 1.0 (TID 17)
15/09/06 02:39:29 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000004_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:29 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 7067 ms on localhost (1/39)
15/09/06 02:39:29 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 2180 bytes result sent to driver
15/09/06 02:39:29 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 18, localhost, ANY, 1707 bytes)
15/09/06 02:39:29 INFO Executor: Running task 17.0 in stage 1.0 (TID 18)
15/09/06 02:39:29 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 7475 ms on localhost (2/39)
15/09/06 02:39:29 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000004_0 start: 268435456 end: 336808298 length: 68372842 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:29 INFO Executor: Finished task 14.0 in stage 1.0 (TID 15). 2180 bytes result sent to driver
15/09/06 02:39:29 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 19, localhost, ANY, 1694 bytes)
15/09/06 02:39:29 INFO Executor: Running task 18.0 in stage 1.0 (TID 19)
15/09/06 02:39:29 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 15) in 7592 ms on localhost (3/39)
15/09/06 02:39:29 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000012_0 start: 0 end: 134217728 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:29 INFO Executor: Finished task 11.0 in stage 1.0 (TID 12). 2180 bytes result sent to driver
15/09/06 02:39:29 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 20, localhost, ANY, 1699 bytes)
15/09/06 02:39:29 INFO Executor: Running task 19.0 in stage 1.0 (TID 20)
15/09/06 02:39:29 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 12) in 7648 ms on localhost (4/39)
15/09/06 02:39:29 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000012_0 start: 134217728 end: 268435456 length: 134217728 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:31 INFO Executor: Finished task 8.0 in stage 1.0 (TID 9). 2180 bytes result sent to driver
15/09/06 02:39:31 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 21, localhost, ANY, 1710 bytes)
15/09/06 02:39:31 INFO Executor: Running task 20.0 in stage 1.0 (TID 21)
15/09/06 02:39:31 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/partsupp_par/000012_0 start: 268435456 end: 333041820 length: 64606364 hosts: [] requestedSchema: message root {
  optional int32 ps_partkey;
  optional int32 ps_suppkey;
  optional double ps_supplycost;
  optional int32 ps_availqty;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"ps_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"ps_supplycost","type":"double","nullable":true,"metadata":{}},{"name":"ps_availqty","type":"integer","nullable":true,"metadata":{}}]}}}
15/09/06 02:39:31 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 8929 ms on localhost (5/39)
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/09/06 02:39:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/09/06 02:39:32 INFO SparkUI: Stopped Spark web UI at http://192.168.122.56:4040
15/09/06 02:39:32 INFO DAGScheduler: Stopping DAGScheduler
15/09/06 02:39:32 INFO DAGScheduler: Job 1 failed: processCmd at CliDriver.java:423, took 10.203087 s
15/09/06 02:39:32 INFO DAGScheduler: ShuffleMapStage 1 (processCmd at CliDriver.java:423) failed in 9.976 s
15/09/06 02:39:32 INFO DAGScheduler: ShuffleMapStage 2 (processCmd at CliDriver.java:423) failed in 9.931 s
15/09/06 02:39:32 ERROR InsertIntoHadoopFsRelation: Aborting job.
org.apache.spark.SparkException: Job cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:736)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:735)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1475)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1410)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1644)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:74)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anonfun$main$1.apply$mcV$sp(SparkSQLCLIDriver.scala:112)
	at org.apache.spark.util.SparkShutdownHook.run(Utils.scala:2308)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1772)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$6.run(Utils.scala:2260)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
15/09/06 02:39:32 INFO StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@77b59dd
15/09/06 02:39:32 INFO StatsReportListener: task runtime:(count: 5, mean: 7742.200000, stdev: 627.250955, max: 8929.000000, min: 7067.000000)
15/09/06 02:39:32 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:32 INFO StatsReportListener: 	7.1 s	7.1 s	7.1 s	7.5 s	7.6 s	7.6 s	8.9 s	8.9 s	8.9 s
15/09/06 02:39:32 ERROR DefaultWriterContainer: Job job_201509060239_0000 aborted.
15/09/06 02:39:32 ERROR SparkSQLDriver: Failed in [ -- the query
insert overwrite table q11_part_tmp_par
select
  ps_partkey,
  sum(ps_supplycost * ps_availqty) as part_value
from
  nation_par n join supplier_par s on s.s_nationkey = n.n_nationkey and n.n_name = 'RUSSIA'
  join partsupp_par ps on ps.ps_suppkey = s.s_suppkey
group by
    ps_partkey]
org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.insert(commands.scala:166)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.run(commands.scala:139)
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:57)
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:57)
	at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:68)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:88)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:88)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:87)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:950)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:950)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:144)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:128)
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:755)
	at org.apache.spark.sql.hive.thriftserver.AbstractSparkSQLDriver.run(AbstractSparkSQLDriver.scala:57)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:283)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:423)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:359)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:158)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Job cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:736)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:735)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1475)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1410)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1644)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:74)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anonfun$main$1.apply$mcV$sp(SparkSQLCLIDriver.scala:112)
	at org.apache.spark.util.SparkShutdownHook.run(Utils.scala:2308)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1772)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$6.run(Utils.scala:2260)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
15/09/06 02:39:32 INFO StatsReportListener: shuffle bytes written:(count: 5, mean: 27312143.200000, stdev: 386721.235651, max: 27756462.000000, min: 26871468.000000)
15/09/06 02:39:32 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:32 INFO StatsReportListener: 	25.6 MB	25.6 MB	25.6 MB	25.6 MB	26.0 MB	26.5 MB	26.5 MB	26.5 MB	26.5 MB
15/09/06 02:39:32 INFO StatsReportListener: task result size:(count: 5, mean: 2180.000000, stdev: 0.000000, max: 2180.000000, min: 2180.000000)
15/09/06 02:39:32 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:32 INFO StatsReportListener: 	2.1 KB	2.1 KB	2.1 KB	2.1 KB	2.1 KB	2.1 KB	2.1 KB	2.1 KB	2.1 KB
org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.insert(commands.scala:166)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.run(commands.scala:139)
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:57)
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:57)
	at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:68)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:88)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:88)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:87)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:950)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:950)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:144)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:128)
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:755)
	at org.apache.spark.sql.hive.thriftserver.AbstractSparkSQLDriver.run(AbstractSparkSQLDriver.scala:57)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:283)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:423)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:359)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:158)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Job cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:736)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:735)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1475)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1410)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1644)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:74)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anonfun$main$1.apply$mcV$sp(SparkSQLCLIDriver.scala:112)
	at org.apache.spark.util.SparkShutdownHook.run(Utils.scala:2308)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1772)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$6.run(Utils.scala:2260)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)

15/09/06 02:39:32 ERROR CliDriver: org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.insert(commands.scala:166)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.run(commands.scala:139)
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:57)
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:57)
	at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:68)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:88)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:88)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:87)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:950)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:950)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:144)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:128)
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:755)
	at org.apache.spark.sql.hive.thriftserver.AbstractSparkSQLDriver.run(AbstractSparkSQLDriver.scala:57)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:283)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:423)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:359)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:158)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Job cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:736)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:735)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1475)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1410)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1644)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:74)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anonfun$main$1.apply$mcV$sp(SparkSQLCLIDriver.scala:112)
	at org.apache.spark.util.SparkShutdownHook.run(Utils.scala:2308)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(Utils.scala:2278)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1772)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(Utils.scala:2278)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(Utils.scala:2278)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$6.run(Utils.scala:2260)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)

15/09/06 02:39:32 INFO StatsReportListener: executor (non-fetch) time pct: (count: 5, mean: 98.043892, stdev: 0.353923, max: 98.342480, min: 97.580303)
15/09/06 02:39:32 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:32 INFO StatsReportListener: 	98 %	98 %	98 %	98 %	98 %	98 %	98 %	98 %	98 %
15/09/06 02:39:32 INFO StatsReportListener: other time pct: (count: 5, mean: 1.956108, stdev: 0.353923, max: 2.419697, min: 1.657520)
15/09/06 02:39:32 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/09/06 02:39:32 INFO StatsReportListener: 	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %
15/09/06 02:39:32 INFO StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@28ded6f
15/09/06 02:39:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/09/06 02:39:33 INFO Utils: path = /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a, already present as root for deletion.
15/09/06 02:39:33 INFO MemoryStore: MemoryStore cleared
15/09/06 02:39:33 INFO BlockManager: BlockManager stopped
15/09/06 02:39:33 INFO BlockManagerMaster: BlockManagerMaster stopped
15/09/06 02:39:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/09/06 02:39:33 INFO SparkContext: Successfully stopped SparkContext
15/09/06 02:39:33 INFO Utils: Shutdown hook called
15/09/06 02:39:33 INFO Utils: Deleting directory /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6
15/09/06 02:39:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/09/06 02:39:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_72dad8d6-8e0a-4a8c-bb0a-d22867e84c74
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_72dad8d6-8e0a-4a8c-bb0a-d22867e84c74 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_b2662e24-45f9-4ab5-85ae-1fcc2411ef46
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_b2662e24-45f9-4ab5-85ae-1fcc2411ef46 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_9bd1e2cd-0e27-4fab-8499-6364e51b654b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_9bd1e2cd-0e27-4fab-8499-6364e51b654b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_bb33b26d-f380-4006-9abd-57505b589bbc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_bb33b26d-f380-4006-9abd-57505b589bbc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_a0891a28-477b-4fe8-a29f-a0b8fa153245
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_a0891a28-477b-4fe8-a29f-a0b8fa153245 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_84c4b799-31b9-448c-8113-72b4182fb6fa
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_84c4b799-31b9-448c-8113-72b4182fb6fa (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_a86fa148-c2de-4ab5-aba7-4fa1a45871d4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_a86fa148-c2de-4ab5-aba7-4fa1a45871d4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_eeb26cc2-06ea-4688-a34a-86b006778f3c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_eeb26cc2-06ea-4688-a34a-86b006778f3c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_07b7a216-5fcf-4d90-b458-f3abb2c1cb95
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_07b7a216-5fcf-4d90-b458-f3abb2c1cb95 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_c29e04ee-d1df-4d17-a8e3-a568353d5947
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_c29e04ee-d1df-4d17-a8e3-a568353d5947 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_f24a0c54-873f-4672-bc2c-65e016c14d4d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_f24a0c54-873f-4672-bc2c-65e016c14d4d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_c61e46c9-9e09-4ff2-9954-bc77827401cf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_c61e46c9-9e09-4ff2-9954-bc77827401cf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_a2646b29-0c6a-4950-aa1a-97cdbec03759
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_a2646b29-0c6a-4950-aa1a-97cdbec03759 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_1d0a3908-e9fc-4810-b868-b1153dab4049
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_1d0a3908-e9fc-4810-b868-b1153dab4049 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_21709be4-ccd0-483f-8459-b9a276eb0a20
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_21709be4-ccd0-483f-8459-b9a276eb0a20 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_cc49038f-2d8a-42f2-b133-adcf7b515859
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_cc49038f-2d8a-42f2-b133-adcf7b515859 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_e2b8ae44-fdac-4f9e-a8c9-9c596db702cf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_e2b8ae44-fdac-4f9e-a8c9-9c596db702cf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_ba45cd03-454b-4535-b6e1-c26931e70af6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_ba45cd03-454b-4535-b6e1-c26931e70af6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_a05c0791-0bd3-48f8-ad6c-819bf9e57424
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_a05c0791-0bd3-48f8-ad6c-819bf9e57424 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_63f4947f-1c55-4c9c-bf50-da4e41de1f9d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_63f4947f-1c55-4c9c-bf50-da4e41de1f9d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_44590598-8634-4300-afaa-164127b399ea
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_44590598-8634-4300-afaa-164127b399ea (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_f4606521-2c88-42b1-b5c7-1bb44781c9a5
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_f4606521-2c88-42b1-b5c7-1bb44781c9a5 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_23421462-a01a-42bd-9e52-d03a5af03c48
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_23421462-a01a-42bd-9e52-d03a5af03c48 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_128470cc-d64b-41d9-bc17-0ec748781565
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_128470cc-d64b-41d9-bc17-0ec748781565 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_7684aefb-43a7-453e-8018-7d660268fdd6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_7684aefb-43a7-453e-8018-7d660268fdd6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_8088e376-9735-410d-9287-38ee5ae5f635
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_8088e376-9735-410d-9287-38ee5ae5f635 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_32b95e16-e53f-4532-ac37-705486ffcfdd
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_32b95e16-e53f-4532-ac37-705486ffcfdd (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_69499727-ca5e-4305-9ac0-344d008886cf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_69499727-ca5e-4305-9ac0-344d008886cf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_4446c987-fcab-4963-bb95-64dd7a622b4e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_4446c987-fcab-4963-bb95-64dd7a622b4e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_e20c9e3a-b559-4199-acdf-7e3c05eeffc2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_e20c9e3a-b559-4199-acdf-7e3c05eeffc2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_bc7c0069-34a7-4e30-86a2-6cdfd7ace619
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_bc7c0069-34a7-4e30-86a2-6cdfd7ace619 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_d21b9216-17b0-48a3-91aa-05437fba189c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_d21b9216-17b0-48a3-91aa-05437fba189c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_9177148d-e1ae-4011-9e35-5aa64c728f90
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_9177148d-e1ae-4011-9e35-5aa64c728f90 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_c0c6ee5e-dd58-46a9-b1cf-119c3f89593f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_c0c6ee5e-dd58-46a9-b1cf-119c3f89593f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_409fa9ed-48fe-4a61-bbf4-3b6d45b280a7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_409fa9ed-48fe-4a61-bbf4-3b6d45b280a7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_734be624-2a34-477d-bc2e-bbe4b5329f3c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_734be624-2a34-477d-bc2e-bbe4b5329f3c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_b477f37c-431a-4ebf-9ad4-7a4f29c77991
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_b477f37c-431a-4ebf-9ad4-7a4f29c77991 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_5d893a6d-8df2-4d9d-8939-4f3fa8dea2cb
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_5d893a6d-8df2-4d9d-8939-4f3fa8dea2cb (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_09d1b64a-cb10-421e-b59d-5102e819e1da
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_09d1b64a-cb10-421e-b59d-5102e819e1da (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_6828722f-03ba-4633-9519-e1f1989c013d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_6828722f-03ba-4633-9519-e1f1989c013d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_113b8413-c60d-47d8-b051-9faa9bf28e35
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_113b8413-c60d-47d8-b051-9faa9bf28e35 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_1aa1a307-f6b8-414d-8957-e6c9ec805cf2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_1aa1a307-f6b8-414d-8957-e6c9ec805cf2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_cf655900-4b2c-4c1f-917e-1f6e450ce5b9
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_cf655900-4b2c-4c1f-917e-1f6e450ce5b9 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_4f3c2638-f868-47d6-8bfd-7169c743ee76
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_4f3c2638-f868-47d6-8bfd-7169c743ee76 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_af866b35-13b7-4180-bd43-3908b291e5dc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_af866b35-13b7-4180-bd43-3908b291e5dc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_f7cf4cd6-b9f7-44fe-85f1-3295b643b3d4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_f7cf4cd6-b9f7-44fe-85f1-3295b643b3d4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_de10ccc1-f07d-4bcd-8b56-17e2b64ae0ec
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_de10ccc1-f07d-4bcd-8b56-17e2b64ae0ec (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_6ed69883-9a64-490b-87fd-ea950f06efd7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_6ed69883-9a64-490b-87fd-ea950f06efd7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_a762553b-dc7c-43aa-bd84-4d3e48275e6c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_a762553b-dc7c-43aa-bd84-4d3e48275e6c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/36/temp_shuffle_92972494-2ea6-465e-bff8-c88893ff975e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/36/temp_shuffle_92972494-2ea6-465e-bff8-c88893ff975e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_2ef4ba7d-e3aa-4634-910a-f2594d00a142
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_2ef4ba7d-e3aa-4634-910a-f2594d00a142 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_d3c97819-2341-4db2-80c7-bd64d9c3bdf3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_d3c97819-2341-4db2-80c7-bd64d9c3bdf3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_499d14de-6227-40d6-b870-1b6dea5049a1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_499d14de-6227-40d6-b870-1b6dea5049a1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_1c40fe86-5d29-4931-be1d-a74c68ba5cd8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_1c40fe86-5d29-4931-be1d-a74c68ba5cd8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_3e316b50-847c-40e5-b430-8d0d0bf940e0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_3e316b50-847c-40e5-b430-8d0d0bf940e0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_6c1a3f0d-0a78-40b6-9401-829613e1fd2f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_6c1a3f0d-0a78-40b6-9401-829613e1fd2f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_e2c263f9-d685-4426-9568-5d8d33101475
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_e2c263f9-d685-4426-9568-5d8d33101475 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_af0c860b-2486-40d6-ba76-30527f43682c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_af0c860b-2486-40d6-ba76-30527f43682c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_b339fe44-e60b-404e-b5ab-74c9a104b0fb
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_b339fe44-e60b-404e-b5ab-74c9a104b0fb (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_b42038fd-5271-4393-8fe9-d173e1161bea
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_b42038fd-5271-4393-8fe9-d173e1161bea (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_f3c1459c-4efe-4f83-992a-9a6032d7ce82
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_f3c1459c-4efe-4f83-992a-9a6032d7ce82 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_8be60b3e-fa23-492c-ba95-a71404e73771
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_8be60b3e-fa23-492c-ba95-a71404e73771 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_a18323d4-4fa3-4257-a367-aead942a7e47
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_a18323d4-4fa3-4257-a367-aead942a7e47 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_e1ea138e-e064-45f4-ae28-51520b745305
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_e1ea138e-e064-45f4-ae28-51520b745305 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_4ab9e028-29ca-443f-a658-8ec1581958e7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_4ab9e028-29ca-443f-a658-8ec1581958e7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_2e84ab2e-1566-4627-85c3-fb92526f6fd6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_2e84ab2e-1566-4627-85c3-fb92526f6fd6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_53334553-3c34-4d7a-8027-e17147d72ad1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_53334553-3c34-4d7a-8027-e17147d72ad1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_9139b75b-06c7-4960-95bc-a502f346df4e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_9139b75b-06c7-4960-95bc-a502f346df4e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_a78350d8-c2e9-470b-be79-29494d050966
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_a78350d8-c2e9-470b-be79-29494d050966 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_7b9c20ad-6d7d-4cef-8483-2b658ed9a7e4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_7b9c20ad-6d7d-4cef-8483-2b658ed9a7e4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_0d5c262d-cf16-450c-a252-207d9d1ede4b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_0d5c262d-cf16-450c-a252-207d9d1ede4b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_3f1ed120-e3e0-4425-bf6d-a2a2617af578
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_3f1ed120-e3e0-4425-bf6d-a2a2617af578 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_34798f39-0f6a-413e-9a9e-6c3e9ce94142
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_34798f39-0f6a-413e-9a9e-6c3e9ce94142 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_606723b0-229d-40e3-a78e-b394dc522293
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_606723b0-229d-40e3-a78e-b394dc522293 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_02bb628e-64b8-437f-a0ea-e7b229975f3f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_02bb628e-64b8-437f-a0ea-e7b229975f3f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_68a76eaa-7cee-4c91-96c8-bc6be85eebe8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_68a76eaa-7cee-4c91-96c8-bc6be85eebe8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_d49aa439-ce96-4e9d-99d3-e4085e548717
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_d49aa439-ce96-4e9d-99d3-e4085e548717 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_ca021c3d-b10e-48d0-a637-7df3ea10d3bc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_ca021c3d-b10e-48d0-a637-7df3ea10d3bc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_c9d8c809-a357-4cca-b6e8-e2f20705aa86
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_c9d8c809-a357-4cca-b6e8-e2f20705aa86 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_6bfdc45f-e7ea-4829-9ae3-2e43d6c72198
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_6bfdc45f-e7ea-4829-9ae3-2e43d6c72198 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_3c0f19bc-1518-40d9-a77e-903969a6426c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_3c0f19bc-1518-40d9-a77e-903969a6426c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_9f70f115-5a3e-4ac9-a1c4-5fb5f586de83
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_9f70f115-5a3e-4ac9-a1c4-5fb5f586de83 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_d510fc95-5ad5-4535-9db3-37a4d1f87c68
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_d510fc95-5ad5-4535-9db3-37a4d1f87c68 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_b98fdec5-6efa-49e5-8a01-d1a8b95ee087
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_b98fdec5-6efa-49e5-8a01-d1a8b95ee087 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_f27462fc-07d2-4b29-bde7-4068c729b23d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_f27462fc-07d2-4b29-bde7-4068c729b23d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_c318f5d4-93c8-4e54-b82a-e3b2b602d9fc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_c318f5d4-93c8-4e54-b82a-e3b2b602d9fc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_5e4ba4ab-a37b-43e0-b38a-7aa629e4ab1b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_5e4ba4ab-a37b-43e0-b38a-7aa629e4ab1b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_2830f84d-3fbf-4b4e-9c51-d4c46fa92f71
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_2830f84d-3fbf-4b4e-9c51-d4c46fa92f71 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_e0a8e131-f12d-4376-913c-b6befd548c03
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_e0a8e131-f12d-4376-913c-b6befd548c03 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_6503fb78-fe85-434c-9e3a-f02b2e2ebca2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_6503fb78-fe85-434c-9e3a-f02b2e2ebca2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_f0ba5a08-5c98-4af2-8aa3-1614c11830d3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_f0ba5a08-5c98-4af2-8aa3-1614c11830d3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_fad79535-1d8d-4cc1-b88f-2e784185a520
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_fad79535-1d8d-4cc1-b88f-2e784185a520 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_5eafe88c-c686-4eeb-ad22-4e0ae776951b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_5eafe88c-c686-4eeb-ad22-4e0ae776951b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_a1504319-a747-498b-9826-4b362d75b781
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_a1504319-a747-498b-9826-4b362d75b781 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_0828b363-60bd-4b5a-8e42-b718448adf56
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_0828b363-60bd-4b5a-8e42-b718448adf56 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_6b4b18ab-f0a6-419c-8cee-275eb0df2bd7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_6b4b18ab-f0a6-419c-8cee-275eb0df2bd7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_48aded90-4a1e-4b5a-b331-5cb47ccc6f48
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_48aded90-4a1e-4b5a-b331-5cb47ccc6f48 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_48db4b4e-0636-4046-9a89-a744b8fd0a14
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_48db4b4e-0636-4046-9a89-a744b8fd0a14 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_43e36e96-11be-41e0-b230-3e02556c3f67
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_43e36e96-11be-41e0-b230-3e02556c3f67 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_1c96bb49-7c84-4d77-aa4c-0cb68e09352a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_1c96bb49-7c84-4d77-aa4c-0cb68e09352a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_14799343-9b7c-4817-8154-8d4989ab6d1c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_14799343-9b7c-4817-8154-8d4989ab6d1c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_d058c347-d70c-4032-ac79-7f56a8ac4310
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_d058c347-d70c-4032-ac79-7f56a8ac4310 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_6748ba86-2682-4ea9-a2ce-92bfde5329ba
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_6748ba86-2682-4ea9-a2ce-92bfde5329ba (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_92d89db3-e859-4e96-adc7-12fd425299b3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_92d89db3-e859-4e96-adc7-12fd425299b3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_7c562bbb-bd90-4fd5-b01e-70d011b140cc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_7c562bbb-bd90-4fd5-b01e-70d011b140cc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_c3a6e7a5-70d3-48b1-93fa-e7bc0488a7ce
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_c3a6e7a5-70d3-48b1-93fa-e7bc0488a7ce (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_c83dff78-4308-4e57-9e8f-4f0b59e576c1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_c83dff78-4308-4e57-9e8f-4f0b59e576c1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_13d89f64-f8f4-4ec9-a933-d103e04f9b4b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_13d89f64-f8f4-4ec9-a933-d103e04f9b4b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_bb775fe5-1aa5-4d08-9e7b-702edcded1bc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_bb775fe5-1aa5-4d08-9e7b-702edcded1bc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_4bef275f-11fe-4dcc-bbca-f9524c64d4bd
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_4bef275f-11fe-4dcc-bbca-f9524c64d4bd (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_08ec3467-adc2-4657-9ffc-101d27a3d547
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_08ec3467-adc2-4657-9ffc-101d27a3d547 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_b6c9a6eb-26bb-4863-be7c-6d66fc69b9fc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_b6c9a6eb-26bb-4863-be7c-6d66fc69b9fc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_88d244bb-dc57-436c-8fcc-e67b7e6ca97c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_88d244bb-dc57-436c-8fcc-e67b7e6ca97c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/36/temp_shuffle_b31bd9b3-a797-44f2-be93-7ae5219f0f17
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/36/temp_shuffle_b31bd9b3-a797-44f2-be93-7ae5219f0f17 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_14bba3ac-860a-400f-af40-2cce2d9e3c84
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_14bba3ac-860a-400f-af40-2cce2d9e3c84 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_f32851cd-9e52-4e0b-9dc0-aaeee8ecf1e8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_f32851cd-9e52-4e0b-9dc0-aaeee8ecf1e8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_f2ad0139-2122-4b7c-bf08-ec043373afb0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_f2ad0139-2122-4b7c-bf08-ec043373afb0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_2a4faacd-7f04-458c-b3c1-cb472642036b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_2a4faacd-7f04-458c-b3c1-cb472642036b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_18f23a31-93d4-48fc-9fd8-41142ca553df
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_18f23a31-93d4-48fc-9fd8-41142ca553df (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_d6b82ea8-f33a-4522-8750-6059d72a5902
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_d6b82ea8-f33a-4522-8750-6059d72a5902 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_56c26ad2-54b5-416f-a25f-59ede8f98d12
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_56c26ad2-54b5-416f-a25f-59ede8f98d12 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_6cf0ca9a-6a08-47e4-b25e-c2c888d7ddf1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_6cf0ca9a-6a08-47e4-b25e-c2c888d7ddf1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_6b7eb5c3-54bf-44ec-bc98-bbe0e269ddb6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_6b7eb5c3-54bf-44ec-bc98-bbe0e269ddb6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_dff15ffa-396b-49fe-bb94-6440d8bbf80b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_dff15ffa-396b-49fe-bb94-6440d8bbf80b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_c1481a32-a901-41e5-a569-d5411e687a7b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_c1481a32-a901-41e5-a569-d5411e687a7b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_6c1e666c-0a12-4950-8685-c6a42278094b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_6c1e666c-0a12-4950-8685-c6a42278094b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_9e5cf933-2240-46d3-a87e-aa9b0c9adf06
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_9e5cf933-2240-46d3-a87e-aa9b0c9adf06 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_051bee91-0dac-4571-be0f-6adeb4aafbf3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_051bee91-0dac-4571-be0f-6adeb4aafbf3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_f6450c66-1d11-4124-b63a-b4f5fc5a9212
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_f6450c66-1d11-4124-b63a-b4f5fc5a9212 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_65c000f4-029b-4c7b-b29e-cdd38dcb7cc8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_65c000f4-029b-4c7b-b29e-cdd38dcb7cc8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_87af5b9e-bb05-4c46-86be-f4b61be28b48
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_87af5b9e-bb05-4c46-86be-f4b61be28b48 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_b7b7d1e5-697b-4f4e-a1d3-c6f854d71d8e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_b7b7d1e5-697b-4f4e-a1d3-c6f854d71d8e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_fb57f0b3-1cae-4dd7-acd6-2edd092300df
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_fb57f0b3-1cae-4dd7-acd6-2edd092300df (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_ec2460e8-4cd7-41da-ace0-c4a4beaabc69
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_ec2460e8-4cd7-41da-ace0-c4a4beaabc69 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_5ef253db-6f56-4fd0-8f3d-a65f8c0110ef
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_5ef253db-6f56-4fd0-8f3d-a65f8c0110ef (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_184722c1-3aaa-4a90-9caa-a0d487ad2665
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_184722c1-3aaa-4a90-9caa-a0d487ad2665 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_ed621402-9e13-4708-88ec-66e6a7cf551b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_ed621402-9e13-4708-88ec-66e6a7cf551b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_bb33579c-e858-4107-ac71-f0873e09b14c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_bb33579c-e858-4107-ac71-f0873e09b14c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1d/temp_shuffle_78af9ea9-5573-47d9-89fd-26ca3d8fd5b5
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1d/temp_shuffle_78af9ea9-5573-47d9-89fd-26ca3d8fd5b5 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_3ffc5b3e-c1e9-4f77-a818-de23b59a9f75
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_3ffc5b3e-c1e9-4f77-a818-de23b59a9f75 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_658ad53e-8bf1-4eee-995a-fe59da496cc3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_658ad53e-8bf1-4eee-995a-fe59da496cc3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_7831229f-27d2-4611-9427-a4824640b5c9
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_7831229f-27d2-4611-9427-a4824640b5c9 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_998c847c-e62f-436b-bf1f-7e815655a82f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_998c847c-e62f-436b-bf1f-7e815655a82f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_9d8413d0-4cd3-436c-9545-19358510a8ae
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_9d8413d0-4cd3-436c-9545-19358510a8ae (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_aad12322-8ce6-4546-b092-22d9eb5dd1d3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_aad12322-8ce6-4546-b092-22d9eb5dd1d3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_9a485c62-77b5-470d-a374-7c01818ae6b2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_9a485c62-77b5-470d-a374-7c01818ae6b2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_e316650b-4ab9-49f5-b2a3-271d2eab341a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_e316650b-4ab9-49f5-b2a3-271d2eab341a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_521a66c3-3f68-4850-bc9b-f02c4879472e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1b/temp_shuffle_521a66c3-3f68-4850-bc9b-f02c4879472e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_20cdb587-f574-4900-9ccf-1f8cb6a964b4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_20cdb587-f574-4900-9ccf-1f8cb6a964b4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_0576125e-0e3c-4ee9-b43d-1fb612060751
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_0576125e-0e3c-4ee9-b43d-1fb612060751 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_04f9bb63-7404-4634-8697-4fca3474f289
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_04f9bb63-7404-4634-8697-4fca3474f289 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_1e65a5b1-ec66-42f4-8407-31c160a79bb9
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_1e65a5b1-ec66-42f4-8407-31c160a79bb9 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_fc76b028-c27b-4119-b019-debf48a0058f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_fc76b028-c27b-4119-b019-debf48a0058f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_af9f1fee-7ac8-4355-b6dd-02f334bf1ff1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_af9f1fee-7ac8-4355-b6dd-02f334bf1ff1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_3bf0b7b7-b444-41ae-a1c1-e73735363e8f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_3bf0b7b7-b444-41ae-a1c1-e73735363e8f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_fd119580-bab6-45f2-80fe-750530f01a24
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_fd119580-bab6-45f2-80fe-750530f01a24 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_325f24c7-a38f-4db4-990d-03493bab1394
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_325f24c7-a38f-4db4-990d-03493bab1394 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_aae24cd5-2106-4518-a48c-4d0aa5241ee6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_aae24cd5-2106-4518-a48c-4d0aa5241ee6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_32cbb45a-8440-46ba-97e5-d6c4a8d4778e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_32cbb45a-8440-46ba-97e5-d6c4a8d4778e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_2d332212-b443-401b-9896-e8439cebbaff
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_2d332212-b443-401b-9896-e8439cebbaff (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_4ac19ac3-fef9-4c1a-b233-2d23404b3b3d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_4ac19ac3-fef9-4c1a-b233-2d23404b3b3d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_880af8fe-d150-4bed-ae41-ef68ac699306
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_880af8fe-d150-4bed-ae41-ef68ac699306 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_4e475188-873a-46d4-90cb-c4648160f724
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_4e475188-873a-46d4-90cb-c4648160f724 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_6feb769e-3453-4e09-b270-8c7616152bf6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_6feb769e-3453-4e09-b270-8c7616152bf6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_645051f1-5c86-46b4-8235-2a4577151244
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_645051f1-5c86-46b4-8235-2a4577151244 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_0c8d80f5-8608-4ad1-b299-037e2a71b73b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_0c8d80f5-8608-4ad1-b299-037e2a71b73b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_974fc5bc-576b-4506-8814-dc51fa6fafb4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_974fc5bc-576b-4506-8814-dc51fa6fafb4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_59e6962e-c0cc-4df7-916b-6b3ff11a52f0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/39/temp_shuffle_59e6962e-c0cc-4df7-916b-6b3ff11a52f0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_761c219b-e570-4da0-a875-1369104fd1a3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_761c219b-e570-4da0-a875-1369104fd1a3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_d537b0a2-954c-4efc-863b-aaa961e84104
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_d537b0a2-954c-4efc-863b-aaa961e84104 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_9925b971-6982-4f14-b1fc-2d71063687b4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_9925b971-6982-4f14-b1fc-2d71063687b4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_e32916aa-a9a1-409e-9479-5e1f88a1f3b2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_e32916aa-a9a1-409e-9479-5e1f88a1f3b2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_324280f8-4d63-4ba5-b70c-6f0fe3c9c343
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_324280f8-4d63-4ba5-b70c-6f0fe3c9c343 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_086e992b-cb18-4183-9796-831997901368
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_086e992b-cb18-4183-9796-831997901368 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_38dae133-c97d-4a9e-883a-4a95360151ab
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_38dae133-c97d-4a9e-883a-4a95360151ab (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_d4fbecc1-3544-4c78-86f4-88cb8dd3b4d3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_d4fbecc1-3544-4c78-86f4-88cb8dd3b4d3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_fb133436-f1e4-4b24-a42d-c077556938a8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_fb133436-f1e4-4b24-a42d-c077556938a8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_43e80a17-cd12-49ca-8aee-32b000f0620c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_43e80a17-cd12-49ca-8aee-32b000f0620c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/31/temp_shuffle_5bedc699-a546-4c7f-9a94-5e9e1c0cafa5
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/31/temp_shuffle_5bedc699-a546-4c7f-9a94-5e9e1c0cafa5 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_081dd2bf-9cc3-41be-8dcb-3c63649f4787
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_081dd2bf-9cc3-41be-8dcb-3c63649f4787 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_86bdd004-f9a0-40f8-abce-87243d218560
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_86bdd004-f9a0-40f8-abce-87243d218560 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_d675b412-328d-4414-a2a8-4f1e5bfcc126
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_d675b412-328d-4414-a2a8-4f1e5bfcc126 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_f1c371e8-354c-4ddc-acde-32d62e5c4d35
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/28/temp_shuffle_f1c371e8-354c-4ddc-acde-32d62e5c4d35 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_67460744-ec81-4f7d-8bcc-0d129699a72d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_67460744-ec81-4f7d-8bcc-0d129699a72d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_6a30cf31-7c77-4223-8843-027f0fb263b3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_6a30cf31-7c77-4223-8843-027f0fb263b3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_782a4ffe-2cd9-4e28-a9c0-cc15426a8d83
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_782a4ffe-2cd9-4e28-a9c0-cc15426a8d83 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_f142f223-43e5-4084-978b-e2253443b71b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_f142f223-43e5-4084-978b-e2253443b71b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_0ce63989-bde7-4c1c-914d-e30c14820087
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_0ce63989-bde7-4c1c-914d-e30c14820087 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_5af5ddf2-b9d9-4dbe-8a0a-95b6253d4e30
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_5af5ddf2-b9d9-4dbe-8a0a-95b6253d4e30 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_917d7dc9-7c4c-4c0e-953e-d02a94833ebf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_917d7dc9-7c4c-4c0e-953e-d02a94833ebf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_a47d062b-a15b-48de-93f9-27df73dafa04
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_a47d062b-a15b-48de-93f9-27df73dafa04 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_a6bd1451-26aa-4dd8-be34-3760c2c5587e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_a6bd1451-26aa-4dd8-be34-3760c2c5587e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_6b3ee157-a192-4b04-b526-c02dc00014d8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_6b3ee157-a192-4b04-b526-c02dc00014d8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_707c3db5-49ba-4f12-85ff-afb0d3d19431
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_707c3db5-49ba-4f12-85ff-afb0d3d19431 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_e6275735-5988-4ad6-8c60-a9347c6fede3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_e6275735-5988-4ad6-8c60-a9347c6fede3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_30438748-80e7-4a18-b90c-85d493854701
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_30438748-80e7-4a18-b90c-85d493854701 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_c78bce38-6169-42ca-8cfa-8ed4c0424fdf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_c78bce38-6169-42ca-8cfa-8ed4c0424fdf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_27761910-7a7c-44a7-8266-507d84fd26a8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_27761910-7a7c-44a7-8266-507d84fd26a8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_e4ad4033-9fc3-49a7-8d80-3d025943d4c9
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_e4ad4033-9fc3-49a7-8d80-3d025943d4c9 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_8aaf7549-add2-4d6a-a3ad-67c5aae3edcf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_8aaf7549-add2-4d6a-a3ad-67c5aae3edcf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_e313f85d-27c3-48a3-a920-f0651fcc7619
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_e313f85d-27c3-48a3-a920-f0651fcc7619 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_7ccda602-ea4f-40c2-941a-0be3cf255a73
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0b/temp_shuffle_7ccda602-ea4f-40c2-941a-0be3cf255a73 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_38331f42-ade3-4451-a725-7ff97f2002d8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_38331f42-ade3-4451-a725-7ff97f2002d8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_f4fbd21d-dd8e-49fe-b745-c672fc9b1764
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_f4fbd21d-dd8e-49fe-b745-c672fc9b1764 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_7e3a3e5b-8ab5-4836-8997-219de4fbd2dd
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_7e3a3e5b-8ab5-4836-8997-219de4fbd2dd (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_0c8447a4-3894-4f4d-acab-68f6d554e806
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_0c8447a4-3894-4f4d-acab-68f6d554e806 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_9d0e0a08-492d-4274-93f5-58bba5994202
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_9d0e0a08-492d-4274-93f5-58bba5994202 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_30460c5a-577f-4f72-8401-c4f6b397e545
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_30460c5a-577f-4f72-8401-c4f6b397e545 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_54cd832b-8e85-4a1c-84e3-e0fa5c989c0a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_54cd832b-8e85-4a1c-84e3-e0fa5c989c0a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_b6090d4a-2743-4975-b3c2-bddb9b661b59
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_b6090d4a-2743-4975-b3c2-bddb9b661b59 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_e1ebcfac-fb5a-462d-95c0-c636cb6e971e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_e1ebcfac-fb5a-462d-95c0-c636cb6e971e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_142b5ea8-0f64-4e24-9f98-8291e9d8a030
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_142b5ea8-0f64-4e24-9f98-8291e9d8a030 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_c1793da6-b072-4389-8744-a37e9ef7119d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_c1793da6-b072-4389-8744-a37e9ef7119d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_868004c9-fed0-415f-a851-38d3376cec92
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_868004c9-fed0-415f-a851-38d3376cec92 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_bc16f232-cb5f-4e3e-8237-c3b307af0ef8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_bc16f232-cb5f-4e3e-8237-c3b307af0ef8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_39f3a042-ef3d-4bfb-bf3e-bfa98bfab2e4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_39f3a042-ef3d-4bfb-bf3e-bfa98bfab2e4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2d/temp_shuffle_bbcf0901-858f-4c37-9ebd-5bae796d92de
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2d/temp_shuffle_bbcf0901-858f-4c37-9ebd-5bae796d92de (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_095fe2e1-46eb-46ec-a61b-d1e4a9eeb594
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_095fe2e1-46eb-46ec-a61b-d1e4a9eeb594 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_9cb283b2-d620-4d1e-a13d-16a81dd7afc4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_9cb283b2-d620-4d1e-a13d-16a81dd7afc4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_f9e62095-4acb-4602-b4a9-a4764a24db04
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_f9e62095-4acb-4602-b4a9-a4764a24db04 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_697a9810-582f-4709-ac40-f84bc09928d7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_697a9810-582f-4709-ac40-f84bc09928d7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/09/temp_shuffle_19ac44d1-06e2-4577-a47c-282decf46cf5
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/09/temp_shuffle_19ac44d1-06e2-4577-a47c-282decf46cf5 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1d/temp_shuffle_c12eed55-402a-477f-8741-c881b1158008
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1d/temp_shuffle_c12eed55-402a-477f-8741-c881b1158008 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_af556c9e-32d4-4d45-8732-a694d091c260
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_af556c9e-32d4-4d45-8732-a694d091c260 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_730a0f33-1800-44b5-94de-430bdf820dd6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_730a0f33-1800-44b5-94de-430bdf820dd6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_24b67520-e517-4835-9aac-9de6a610d784
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_24b67520-e517-4835-9aac-9de6a610d784 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_32faa73c-04db-4a69-af52-7277165c73f4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_32faa73c-04db-4a69-af52-7277165c73f4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 INFO Utils: Deleting directory /tmp/spark-085fb58c-5e2f-4bb8-a311-13bd30b16bfe
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_3d4896f6-cc8c-4fb0-b23e-4e97cdb9e541
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_3d4896f6-cc8c-4fb0-b23e-4e97cdb9e541 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_b660f3ad-8081-42dd-b48a-7bba38e781e4
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_b660f3ad-8081-42dd-b48a-7bba38e781e4 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_6e42c5ae-efbb-48e5-a3e3-dbb7951d1833
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_6e42c5ae-efbb-48e5-a3e3-dbb7951d1833 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_d2ae04da-4e2b-4228-9950-62c4ae558163
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_d2ae04da-4e2b-4228-9950-62c4ae558163 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_92f44660-7426-4d7a-ac68-8a9cdc3a5af8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_92f44660-7426-4d7a-ac68-8a9cdc3a5af8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_737b5bb1-9ed9-4127-92ff-3b3fdb221fe1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_737b5bb1-9ed9-4127-92ff-3b3fdb221fe1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_1b1e66a1-0abe-4a86-a382-01fb02d56dbf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_1b1e66a1-0abe-4a86-a382-01fb02d56dbf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_e1bbb31a-6586-4cbf-818b-369ddd311c07
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_e1bbb31a-6586-4cbf-818b-369ddd311c07 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2b/temp_shuffle_b2b93b95-e35a-40d5-8342-bf491573773b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2b/temp_shuffle_b2b93b95-e35a-40d5-8342-bf491573773b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_b9d97dd2-6228-4207-9810-d590b85160ad
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_b9d97dd2-6228-4207-9810-d590b85160ad (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_ec20e928-eb78-4467-8348-e23602e70a90
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/29/temp_shuffle_ec20e928-eb78-4467-8348-e23602e70a90 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_ccd2c549-a349-4744-a103-ffeeb523df0a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_ccd2c549-a349-4744-a103-ffeeb523df0a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_494ec28a-278b-49e9-ac8e-526d76671891
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_494ec28a-278b-49e9-ac8e-526d76671891 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_66c50043-6eed-43f0-a24b-5c9b1a7668bd
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_66c50043-6eed-43f0-a24b-5c9b1a7668bd (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/36/temp_shuffle_6197f966-fc6f-452d-90cf-91feaa24794f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/36/temp_shuffle_6197f966-fc6f-452d-90cf-91feaa24794f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_25d97570-c6df-4ba5-a991-250015f8ce98
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_25d97570-c6df-4ba5-a991-250015f8ce98 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_69941da5-b18b-4bb6-8be0-d77c7caac466
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_69941da5-b18b-4bb6-8be0-d77c7caac466 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_ebef403b-0d7c-4d27-9ee2-17d064917f5c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_ebef403b-0d7c-4d27-9ee2-17d064917f5c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 INFO Utils: Deleting directory /tmp/spark-6ffd60df-a2a9-42b9-89fc-180a97854955
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_89ec08ae-7e53-46df-b237-b525e83d57ff
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_89ec08ae-7e53-46df-b237-b525e83d57ff (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_68f39aa7-3212-4fdd-bfad-4e0c36d2ca11
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_68f39aa7-3212-4fdd-bfad-4e0c36d2ca11 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_7bd42638-1a2b-455c-ada3-71cf2d387da0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_7bd42638-1a2b-455c-ada3-71cf2d387da0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_a694975f-8586-4d9d-aaa3-81ec5574cc81
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/35/temp_shuffle_a694975f-8586-4d9d-aaa3-81ec5574cc81 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_ee0cde33-d06c-4585-8804-2e848b3dfbab
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_ee0cde33-d06c-4585-8804-2e848b3dfbab (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_9c03bca8-bccb-4000-96f6-af2ca5db1833
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_9c03bca8-bccb-4000-96f6-af2ca5db1833 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_d8d4d948-656b-4e52-aff6-f759940aff70
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_d8d4d948-656b-4e52-aff6-f759940aff70 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_4c129511-5fa5-42aa-8d9e-4e6f643ee176
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_4c129511-5fa5-42aa-8d9e-4e6f643ee176 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_185850c2-885a-4ba9-8ee4-e8a5eb7de099
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_185850c2-885a-4ba9-8ee4-e8a5eb7de099 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_1651c4c6-c50d-4a15-afed-769b9c7c8870
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_1651c4c6-c50d-4a15-afed-769b9c7c8870 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_1a1038bc-fd12-4a12-940d-a6594229c2f2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_1a1038bc-fd12-4a12-940d-a6594229c2f2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_408c8803-6b48-43b8-95eb-e26e4ac04253
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_408c8803-6b48-43b8-95eb-e26e4ac04253 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_6f2da97a-c309-4dc3-b340-59e7161defce
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_6f2da97a-c309-4dc3-b340-59e7161defce (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_679e4b8a-f360-47b2-bc03-c39ae1e46377
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_679e4b8a-f360-47b2-bc03-c39ae1e46377 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_779c89b7-81d7-46d8-b442-e44773a9a381
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_779c89b7-81d7-46d8-b442-e44773a9a381 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_db26f0cc-a196-47ed-ac58-d08a2f898254
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_db26f0cc-a196-47ed-ac58-d08a2f898254 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_567f31ac-2010-4430-96e2-5a01fee43ffb
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_567f31ac-2010-4430-96e2-5a01fee43ffb (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_3286de6e-021f-45dc-a73e-5df1282fa6c7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_3286de6e-021f-45dc-a73e-5df1282fa6c7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_67394462-e824-4bfd-9cf1-fa67d7e52cfb
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_67394462-e824-4bfd-9cf1-fa67d7e52cfb (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_8fd6ab6f-59d0-4c6c-bd12-223e4402d638
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_8fd6ab6f-59d0-4c6c-bd12-223e4402d638 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_8bbfe283-9550-4a77-aa43-9cf20ad8038b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_8bbfe283-9550-4a77-aa43-9cf20ad8038b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_4fefa886-7f2d-4103-84ab-cedb1b2f0ed1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_4fefa886-7f2d-4103-84ab-cedb1b2f0ed1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_11fe6871-24eb-494d-a966-530f4dcf49e1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/22/temp_shuffle_11fe6871-24eb-494d-a966-530f4dcf49e1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_9f020278-1638-43a0-8fcc-dbec9eefd2a2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_9f020278-1638-43a0-8fcc-dbec9eefd2a2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_bf812ece-0b16-4b81-8f4b-7a040a58ebf2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3e/temp_shuffle_bf812ece-0b16-4b81-8f4b-7a040a58ebf2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2d/temp_shuffle_4465d026-373b-4eea-b570-8c432a5df948
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2d/temp_shuffle_4465d026-373b-4eea-b570-8c432a5df948 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_5064db67-1506-4557-a365-7eefd2c12c76
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_5064db67-1506-4557-a365-7eefd2c12c76 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_2da00d3e-063e-4516-88f8-35f0165e243c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_2da00d3e-063e-4516-88f8-35f0165e243c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/02/temp_shuffle_bd2e8f9a-fa4b-4c16-901e-38c1ce2e4b4d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/02/temp_shuffle_bd2e8f9a-fa4b-4c16-901e-38c1ce2e4b4d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/02/temp_shuffle_aa1d5596-4811-4710-a105-f8de61bf44df
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/02/temp_shuffle_aa1d5596-4811-4710-a105-f8de61bf44df (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_0692adfe-d27a-42cc-b60d-d3f155e9731c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_0692adfe-d27a-42cc-b60d-d3f155e9731c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_ec8ed373-a8ca-4fdd-b2b1-d0924c2c6ef5
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_ec8ed373-a8ca-4fdd-b2b1-d0924c2c6ef5 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_ba20ee86-1ff0-45ca-8300-2dadb9811990
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/15/temp_shuffle_ba20ee86-1ff0-45ca-8300-2dadb9811990 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_d10665ce-71ab-4fd5-865d-adf2a312634e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_d10665ce-71ab-4fd5-865d-adf2a312634e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_728db91e-3dfd-4815-9359-525efbd74247
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_728db91e-3dfd-4815-9359-525efbd74247 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/31/temp_shuffle_a0c806d3-93a7-40e0-a24b-155072d9c2b1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/31/temp_shuffle_a0c806d3-93a7-40e0-a24b-155072d9c2b1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_b59195da-7f44-4a3f-a537-fa95c768a766
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_b59195da-7f44-4a3f-a537-fa95c768a766 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_a81a814e-f152-4b6b-b5a2-54d6a4564b17
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_a81a814e-f152-4b6b-b5a2-54d6a4564b17 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_917f28ff-b0e1-452b-ace7-e2e67e85f75c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_917f28ff-b0e1-452b-ace7-e2e67e85f75c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_248793d0-eaa9-4292-822c-62d4e1a0a083
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_248793d0-eaa9-4292-822c-62d4e1a0a083 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_d544b50a-feae-4e33-b76b-d775263ca7e7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_d544b50a-feae-4e33-b76b-d775263ca7e7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_1c166690-a657-4ad0-88b1-79808b018a0b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/12/temp_shuffle_1c166690-a657-4ad0-88b1-79808b018a0b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_43dbd6a0-5d1d-4bca-a802-c9add475ff2b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_43dbd6a0-5d1d-4bca-a802-c9add475ff2b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/02/temp_shuffle_fa74a3fd-e98e-4b32-b3f1-e2091974fe43
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/02/temp_shuffle_fa74a3fd-e98e-4b32-b3f1-e2091974fe43 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_d3eb4c04-b6c6-4a9f-8ad8-73c12bb00c94
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_d3eb4c04-b6c6-4a9f-8ad8-73c12bb00c94 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_9692d33d-badc-41d6-8617-f5ae08facb54
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/38/temp_shuffle_9692d33d-badc-41d6-8617-f5ae08facb54 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_b3cd776a-1f4f-478f-bae5-d5c8cb840288
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_b3cd776a-1f4f-478f-bae5-d5c8cb840288 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_e747c21b-5fb0-4843-ba68-57fc4796a2d2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_e747c21b-5fb0-4843-ba68-57fc4796a2d2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_75715c28-8b49-4c08-bec0-e4f87433349e
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_75715c28-8b49-4c08-bec0-e4f87433349e (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_922ad864-dc7c-403c-a4a3-68b81696c413
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0c/temp_shuffle_922ad864-dc7c-403c-a4a3-68b81696c413 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_2c6770c5-2eef-407f-9a2a-1999188f740a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_2c6770c5-2eef-407f-9a2a-1999188f740a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_e7a20faf-ec7b-4f25-af29-266bdd3ee6cd
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_e7a20faf-ec7b-4f25-af29-266bdd3ee6cd (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_46f6e90b-012c-4bbb-9c51-e2c64e7f3c8d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3b/temp_shuffle_46f6e90b-012c-4bbb-9c51-e2c64e7f3c8d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_0272cce5-ef41-4d69-8947-85c4728ed04c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/00/temp_shuffle_0272cce5-ef41-4d69-8947-85c4728ed04c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_71d5d846-07be-4e12-b448-65c5a68484a7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_71d5d846-07be-4e12-b448-65c5a68484a7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_ff83b2a7-c5c7-41b5-919b-826e7fd047fc
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_ff83b2a7-c5c7-41b5-919b-826e7fd047fc (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_15e3a517-e520-4af9-b87a-142d8bbe2dad
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_15e3a517-e520-4af9-b87a-142d8bbe2dad (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_3f1f9766-734e-4533-b2f1-658d369aef5d
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2a/temp_shuffle_3f1f9766-734e-4533-b2f1-658d369aef5d (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_29b265e4-ea95-48d3-8acc-0d3e17e44e22
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_29b265e4-ea95-48d3-8acc-0d3e17e44e22 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_d6ebbf0c-9637-416d-bd3b-7f1926c1b205
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_d6ebbf0c-9637-416d-bd3b-7f1926c1b205 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_8593bcd1-d741-4df5-9ed3-5cc07fe3a672
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_8593bcd1-d741-4df5-9ed3-5cc07fe3a672 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_329ba685-0fa6-4767-9a9d-a4a2b641e2b0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/21/temp_shuffle_329ba685-0fa6-4767-9a9d-a4a2b641e2b0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_c9122121-18d8-4f3c-86de-e89fcd78f2b3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_c9122121-18d8-4f3c-86de-e89fcd78f2b3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_d3147e91-101c-48e1-a7cf-1020c3928ef6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_d3147e91-101c-48e1-a7cf-1020c3928ef6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_47d36931-8e1a-4abd-8b88-badc8b3a2f91
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2e/temp_shuffle_47d36931-8e1a-4abd-8b88-badc8b3a2f91 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_c2a0311a-102b-490b-9047-b94f4f64e794
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/11/temp_shuffle_c2a0311a-102b-490b-9047-b94f4f64e794 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_82b9c44a-6abd-4fb7-906a-a4c7dd9fd561
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_82b9c44a-6abd-4fb7-906a-a4c7dd9fd561 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_af39c996-a0f6-47f9-90ec-ef26232e84b0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_af39c996-a0f6-47f9-90ec-ef26232e84b0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_e4b6e51b-ba2d-41b6-b94a-ec4534a69c96
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_e4b6e51b-ba2d-41b6-b94a-ec4534a69c96 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_014e8cf8-6daa-4fa0-a984-73279d0a0e51
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_014e8cf8-6daa-4fa0-a984-73279d0a0e51 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_1c318a0a-1d3a-4bf7-8a58-87a19166c4ac
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_1c318a0a-1d3a-4bf7-8a58-87a19166c4ac (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_ceb6bc14-f388-4621-a2bf-f08f352f8b8f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/30/temp_shuffle_ceb6bc14-f388-4621-a2bf-f08f352f8b8f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_d2afff17-5417-42fc-a761-7e34f33fb162
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/37/temp_shuffle_d2afff17-5417-42fc-a761-7e34f33fb162 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_9c9ec562-29e7-4290-9511-f4d6eecf3e2c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/05/temp_shuffle_9c9ec562-29e7-4290-9511-f4d6eecf3e2c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_9524b929-489b-4e83-9de3-5c49f3d66ed6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1a/temp_shuffle_9524b929-489b-4e83-9de3-5c49f3d66ed6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_186711b7-dbbb-4313-b5e9-81d97d3a0609
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1e/temp_shuffle_186711b7-dbbb-4313-b5e9-81d97d3a0609 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_347b6980-795b-45c7-83b0-9b2ff2766662
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/19/temp_shuffle_347b6980-795b-45c7-83b0-9b2ff2766662 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_668183d0-5fb9-40c1-88b8-e47cc60a2984
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1f/temp_shuffle_668183d0-5fb9-40c1-88b8-e47cc60a2984 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_41ad42b7-b5f0-47f9-8850-d9b2ba5efbca
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_41ad42b7-b5f0-47f9-8850-d9b2ba5efbca (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/03/temp_shuffle_fed0b538-62b7-4da4-bbc3-25f2cd1c9eed
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/03/temp_shuffle_fed0b538-62b7-4da4-bbc3-25f2cd1c9eed (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1d/temp_shuffle_6ef0f3e2-65a5-4f8d-981d-0b36d5888871
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1d/temp_shuffle_6ef0f3e2-65a5-4f8d-981d-0b36d5888871 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_3b0eae58-aa6f-4739-868c-a27e8119d44f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0e/temp_shuffle_3b0eae58-aa6f-4739-868c-a27e8119d44f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_f87c3e09-d1a1-4647-bb82-3d9798917566
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/04/temp_shuffle_f87c3e09-d1a1-4647-bb82-3d9798917566 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_e4fd8b82-bf74-4223-be05-f52f1e53dc6f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_e4fd8b82-bf74-4223-be05-f52f1e53dc6f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_f7d8397f-ef5a-4283-854c-5eeccbfde3f6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_f7d8397f-ef5a-4283-854c-5eeccbfde3f6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_0bfd7e39-483d-465b-9492-134494fe2ecf
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_0bfd7e39-483d-465b-9492-134494fe2ecf (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_b922cada-0a10-4445-bbb8-bc0ef6846ea8
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/06/temp_shuffle_b922cada-0a10-4445-bbb8-bc0ef6846ea8 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_b86392d5-80ef-4a79-b976-fa1973462cab
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/01/temp_shuffle_b86392d5-80ef-4a79-b976-fa1973462cab (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_c64f0780-0196-45c7-90b1-0e6045b2e305
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_c64f0780-0196-45c7-90b1-0e6045b2e305 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_4b584cc6-d745-47e1-9bba-893f4c034bd2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_4b584cc6-d745-47e1-9bba-893f4c034bd2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_4585f7f3-d5b4-40c9-812d-bee6ff5c8b46
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_4585f7f3-d5b4-40c9-812d-bee6ff5c8b46 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_9dfd61c4-e3bf-4ef2-afe2-2a91a07e5bea
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_9dfd61c4-e3bf-4ef2-afe2-2a91a07e5bea (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_e33a5d3b-30cc-41b8-8f10-cedfc7a76c44
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2f/temp_shuffle_e33a5d3b-30cc-41b8-8f10-cedfc7a76c44 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_3fe610f2-8195-4e8e-b8c7-2c7304c7a853
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_3fe610f2-8195-4e8e-b8c7-2c7304c7a853 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_20a6d1e2-de99-4413-9eac-fd900852d00a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_20a6d1e2-de99-4413-9eac-fd900852d00a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_a0bc8012-b897-43ee-b7ae-dde6a0b3be8b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0a/temp_shuffle_a0bc8012-b897-43ee-b7ae-dde6a0b3be8b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_7b46c62b-3039-445e-a7de-4bfb18b81788
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_7b46c62b-3039-445e-a7de-4bfb18b81788 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_237d6b91-aa40-4b23-b9b1-c1d5247f0e74
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_237d6b91-aa40-4b23-b9b1-c1d5247f0e74 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/03/temp_shuffle_8b644102-b6f9-422e-8699-e9618cc8fee6
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/03/temp_shuffle_8b644102-b6f9-422e-8699-e9618cc8fee6 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_7390f440-bb7a-46ec-a189-1eedbb8efe46
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/34/temp_shuffle_7390f440-bb7a-46ec-a189-1eedbb8efe46 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_6d95f307-0e37-4919-8b57-f10f289b39a0
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_6d95f307-0e37-4919-8b57-f10f289b39a0 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_dfaa5337-9c16-4738-b07c-558d1c0f7764
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/26/temp_shuffle_dfaa5337-9c16-4738-b07c-558d1c0f7764 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_8df3b03e-b0d3-4d89-840c-0d9406d9f6d7
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/24/temp_shuffle_8df3b03e-b0d3-4d89-840c-0d9406d9f6d7 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_b158eccf-039a-463a-886c-708b90bcc4c2
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/17/temp_shuffle_b158eccf-039a-463a-886c-708b90bcc4c2 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/09/temp_shuffle_03ae5107-4e10-4e49-9491-45a174469c67
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/09/temp_shuffle_03ae5107-4e10-4e49-9491-45a174469c67 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_bf0337f7-ec9c-4dc4-a79e-6cc10971cabb
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/20/temp_shuffle_bf0337f7-ec9c-4dc4-a79e-6cc10971cabb (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_12427f62-f6c0-4886-98a2-c6868237a9c3
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/07/temp_shuffle_12427f62-f6c0-4886-98a2-c6868237a9c3 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2b/temp_shuffle_b9942e67-0c59-41ae-b3d1-74fe7acb7307
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2b/temp_shuffle_b9942e67-0c59-41ae-b3d1-74fe7acb7307 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_e3aa16ff-a89f-4b83-8d9e-9951dff99061
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/14/temp_shuffle_e3aa16ff-a89f-4b83-8d9e-9951dff99061 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_657af7b6-de62-4047-8144-e99f3528c82b
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/16/temp_shuffle_657af7b6-de62-4047-8144-e99f3528c82b (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_4f3c0047-35d7-412a-ba9e-eeaeda57f625
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/08/temp_shuffle_4f3c0047-35d7-412a-ba9e-eeaeda57f625 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_26b8bcd4-7d85-478a-8081-54703bf03e03
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0d/temp_shuffle_26b8bcd4-7d85-478a-8081-54703bf03e03 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_a09f13bf-5e14-4a4f-908d-3a428e95bae1
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/1c/temp_shuffle_a09f13bf-5e14-4a4f-908d-3a428e95bae1 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_18faae32-2ec9-4cbb-a16c-7055828ad77a
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/18/temp_shuffle_18faae32-2ec9-4cbb-a16c-7055828ad77a (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2d/temp_shuffle_cdbc5e98-571f-4807-8356-4be8dad42d3f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2d/temp_shuffle_cdbc5e98-571f-4807-8356-4be8dad42d3f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_ad9d19a7-8b34-4abc-8041-54686e9b9aef
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/33/temp_shuffle_ad9d19a7-8b34-4abc-8041-54686e9b9aef (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_259e7813-2e4c-41d3-913b-b828b10767ee
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/27/temp_shuffle_259e7813-2e4c-41d3-913b-b828b10767ee (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_e927078e-7c61-4b01-a14c-c6fd87c9257f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3f/temp_shuffle_e927078e-7c61-4b01-a14c-c6fd87c9257f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_6d82a060-986b-4a91-8fe1-6e79e2413823
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3d/temp_shuffle_6d82a060-986b-4a91-8fe1-6e79e2413823 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_ff354992-5203-4435-9b8a-824ef4b7cc30
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/2c/temp_shuffle_ff354992-5203-4435-9b8a-824ef4b7cc30 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_2697e3f3-5277-4824-8449-7d27e20d98db
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_2697e3f3-5277-4824-8449-7d27e20d98db (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_6ff7dbb4-16ba-405b-be00-4744cd96f8be
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3a/temp_shuffle_6ff7dbb4-16ba-405b-be00-4744cd96f8be (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_b2a3ffb9-f496-4253-b73e-5050ce793656
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/32/temp_shuffle_b2a3ffb9-f496-4253-b73e-5050ce793656 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_e33b617f-42fd-4e9b-b718-f27eab3db26c
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/23/temp_shuffle_e33b617f-42fd-4e9b-b718-f27eab3db26c (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_3fbdfb8e-36de-487f-a4fd-5a8da1c1a1ee
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_3fbdfb8e-36de-487f-a4fd-5a8da1c1a1ee (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_26f63574-7330-45c1-b829-1099f1e84949
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/3c/temp_shuffle_26f63574-7330-45c1-b829-1099f1e84949 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_fbc85957-5fe8-49e0-ac00-162c95099b7f
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/25/temp_shuffle_fbc85957-5fe8-49e0-ac00-162c95099b7f (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_018d1075-dc1a-4ea2-8997-ad8ed7f75a33
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/0f/temp_shuffle_018d1075-dc1a-4ea2-8997-ad8ed7f75a33 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_e855ace0-a898-4a2e-a664-9cfc63d2b6df
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/10/temp_shuffle_e855ace0-a898-4a2e-a664-9cfc63d2b6df (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/09/06 02:39:33 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_765d1de0-1a1f-46e6-be0a-391735cd7b02
java.io.FileNotFoundException: /tmp/spark-470efb30-af5d-4529-8617-d8d4cf7c12b6/blockmgr-504bf804-b672-403f-8a9f-205cc48e770a/13/temp_shuffle_765d1de0-1a1f-46e6-be0a-391735cd7b02 (No such file or directory)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(BlockObjectWriter.scala:189)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:807)
	at org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2.apply(ExternalSorter.scala:806)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.collection.ExternalSorter.stop(ExternalSorter.scala:806)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.stop(SortShuffleWriter.scala:94)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:76)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
