 -- the query
insert into table q6_forecast_revenue_change_par 
select sum(l_extendedprice*l_discount) as revenue
from lineitem_par
where 
  l_shipdate >= '1993-01-01'
  and l_shipdate < '1994-01-01'
  and l_discount >= 0.03 and l_discount <= 0.05
  and l_quantity < 24;
15/08/15 14:43:47 INFO metastore: Trying to connect to metastore with URI thrift://sandbox.hortonworks.com:9083
15/08/15 14:43:47 INFO metastore: Connected to metastore.
15/08/15 14:43:48 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/08/15 14:43:48 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:48 INFO SparkContext: Running Spark version 1.4.1
15/08/15 14:43:48 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:48 INFO SecurityManager: Changing view acls to: hive
15/08/15 14:43:48 INFO SecurityManager: Changing modify acls to: hive
15/08/15 14:43:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hive); users with modify permissions: Set(hive)
15/08/15 14:43:49 INFO Slf4jLogger: Slf4jLogger started
15/08/15 14:43:49 INFO Remoting: Starting remoting
15/08/15 14:43:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.122.56:54746]
15/08/15 14:43:49 INFO Utils: Successfully started service 'sparkDriver' on port 54746.
15/08/15 14:43:49 INFO SparkEnv: Registering MapOutputTracker
15/08/15 14:43:49 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:49 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:49 INFO SparkEnv: Registering BlockManagerMaster
15/08/15 14:43:49 INFO DiskBlockManager: Created local directory at /tmp/spark-19a8e3f3-9eb3-44f3-ae57-a42bb9383c30/blockmgr-9f82bd38-719a-4927-89ee-9df271e40ef9
15/08/15 14:43:49 INFO MemoryStore: MemoryStore started with capacity 3.1 GB
15/08/15 14:43:49 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-19a8e3f3-9eb3-44f3-ae57-a42bb9383c30/httpd-59d39f6d-05d0-41cb-a4fc-6329afe28128
15/08/15 14:43:49 INFO HttpServer: Starting HTTP Server
15/08/15 14:43:49 INFO Server: jetty-8.y.z-SNAPSHOT
15/08/15 14:43:49 INFO AbstractConnector: Started SocketConnector@0.0.0.0:36046
15/08/15 14:43:49 INFO Utils: Successfully started service 'HTTP file server' on port 36046.
15/08/15 14:43:49 INFO SparkEnv: Registering OutputCommitCoordinator
15/08/15 14:43:49 INFO Server: jetty-8.y.z-SNAPSHOT
15/08/15 14:43:49 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/08/15 14:43:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/08/15 14:43:49 INFO SparkUI: Started SparkUI at http://192.168.122.56:4040
15/08/15 14:43:49 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:49 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:49 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:49 INFO Executor: Starting executor ID driver on host localhost
15/08/15 14:43:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36989.
15/08/15 14:43:50 INFO NettyBlockTransferService: Server created on 36989
15/08/15 14:43:50 INFO BlockManagerMaster: Trying to register BlockManager
15/08/15 14:43:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36989 with 3.1 GB RAM, BlockManagerId(driver, localhost, 36989)
15/08/15 14:43:50 INFO BlockManagerMaster: Registered BlockManager
15/08/15 14:43:50 WARN SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
15/08/15 14:43:50 INFO HiveContext: Initializing execution hive, version 0.13.1
15/08/15 14:43:50 INFO HiveContext: Initializing HiveMetastoreConnection version 0.13.1 using Spark classes.
15/08/15 14:43:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/15 14:43:51 INFO metastore: Trying to connect to metastore with URI thrift://sandbox.hortonworks.com:9083
15/08/15 14:43:51 INFO metastore: Connected to metastore.
15/08/15 14:43:52 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
15/08/15 14:43:52 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
SET spark.sql.hive.version=0.13.1
SET spark.sql.hive.version=0.13.1
15/08/15 14:43:52 INFO ParseDriver: Parsing command: -- the query
insert into table q6_forecast_revenue_change_par 
select sum(l_extendedprice*l_discount) as revenue
from lineitem_par
where 
  l_shipdate >= '1993-01-01'
  and l_shipdate < '1994-01-01'
  and l_discount >= 0.03 and l_discount <= 0.05
  and l_quantity < 24
15/08/15 14:43:52 INFO ParseDriver: Parse Completed
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
15/08/15 14:43:55 INFO MemoryStore: ensureFreeSpace(257472) called with curMem=0, maxMem=3333968363
15/08/15 14:43:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 251.4 KB, free 3.1 GB)
15/08/15 14:43:55 INFO MemoryStore: ensureFreeSpace(22794) called with curMem=257472, maxMem=3333968363
15/08/15 14:43:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.3 KB, free 3.1 GB)
15/08/15 14:43:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36989 (size: 22.3 KB, free: 3.1 GB)
15/08/15 14:43:55 INFO SparkContext: Created broadcast 0 from processCmd at CliDriver.java:423
15/08/15 14:43:55 INFO Exchange: Using SparkSqlSerializer2.
15/08/15 14:43:55 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/08/15 14:43:55 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/08/15 14:43:55 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/08/15 14:43:55 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/08/15 14:43:55 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/08/15 14:43:55 INFO ParquetRelation2: Using default output committer for Parquet: parquet.hadoop.ParquetOutputCommitter
15/08/15 14:43:55 INFO DefaultWriterContainer: Using output committer class parquet.hadoop.ParquetOutputCommitter for appending.
15/08/15 14:43:55 INFO SparkContext: Starting job: processCmd at CliDriver.java:423
15/08/15 14:43:56 INFO deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
15/08/15 14:43:56 INFO deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1$$anon$2: Using Task Side Metadata Split Strategy
15/08/15 14:43:56 INFO DAGScheduler: Registering RDD 5 (processCmd at CliDriver.java:423)
15/08/15 14:43:56 INFO DAGScheduler: Got job 0 (processCmd at CliDriver.java:423) with 1 output partitions (allowLocal=false)
15/08/15 14:43:56 INFO DAGScheduler: Final stage: ResultStage 1(processCmd at CliDriver.java:423)
15/08/15 14:43:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/08/15 14:43:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/08/15 14:43:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at processCmd at CliDriver.java:423), which has no missing parents
15/08/15 14:43:56 INFO MemoryStore: ensureFreeSpace(10512) called with curMem=280266, maxMem=3333968363
15/08/15 14:43:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.3 KB, free 3.1 GB)
15/08/15 14:43:56 INFO MemoryStore: ensureFreeSpace(5105) called with curMem=290778, maxMem=3333968363
15/08/15 14:43:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.1 GB)
15/08/15 14:43:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36989 (size: 5.0 KB, free: 3.1 GB)
15/08/15 14:43:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
15/08/15 14:43:56 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at processCmd at CliDriver.java:423)
15/08/15 14:43:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
15/08/15 14:43:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, ANY, 1792 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, ANY, 1795 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, ANY, 1792 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, ANY, 1793 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, ANY, 1792 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, ANY, 1795 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, ANY, 1795 bytes)
15/08/15 14:43:56 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, ANY, 1791 bytes)
15/08/15 14:43:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/08/15 14:43:56 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
15/08/15 14:43:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/08/15 14:43:56 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
15/08/15 14:43:56 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
15/08/15 14:43:56 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
15/08/15 14:43:56 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
15/08/15 14:43:56 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000005_0 start: 0 end: 26505368 length: 26505368 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000006_0 start: 0 end: 26243215 length: 26243215 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000002_0 start: 0 end: 26234990 length: 26234990 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000007_0 start: 0 end: 26536257 length: 26536257 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000004_0 start: 0 end: 26235204 length: 26235204 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000003_0 start: 0 end: 26210131 length: 26210131 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000000_0 start: 0 end: 26485016 length: 26485016 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO ParquetRelation2$$anonfun$buildScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/lineitem_par/000001_0 start: 0 end: 26576747 length: 26576747 hosts: [] requestedSchema: message root {
  optional double l_extendedprice;
  optional double l_discount;
  optional binary l_shipdate (UTF8);
  optional double l_quantity;
}
 readSupportMetadata: {org.apache.spark.sql.parquet.row.metadata={"type":"struct","fields":[{"name":"l_orderkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_partkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_suppkey","type":"integer","nullable":true,"metadata":{}},{"name":"l_linenumber","type":"integer","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}},{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_tax","type":"double","nullable":true,"metadata":{}},{"name":"l_returnflag","type":"string","nullable":true,"metadata":{}},{"name":"l_linestatus","type":"string","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_commitdate","type":"string","nullable":true,"metadata":{}},{"name":"l_receiptdate","type":"string","nullable":true,"metadata":{}},{"name":"l_shipinstruct","type":"string","nullable":true,"metadata":{}},{"name":"l_shipmode","type":"string","nullable":true,"metadata":{}},{"name":"l_comment","type":"string","nullable":true,"metadata":{}}]}, org.apache.spark.sql.parquet.row.requested_schema={"type":"struct","fields":[{"name":"l_extendedprice","type":"double","nullable":true,"metadata":{}},{"name":"l_discount","type":"double","nullable":true,"metadata":{}},{"name":"l_shipdate","type":"string","nullable":true,"metadata":{}},{"name":"l_quantity","type":"double","nullable":true,"metadata":{}}]}}}
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:56 INFO CodecPool: Got brand-new decompressor [.snappy]
15/08/15 14:43:57 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1925 bytes result sent to driver
15/08/15 14:43:57 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1661 ms on localhost (1/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1662 ms on localhost (2/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 1659 ms on localhost (3/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 1660 ms on localhost (4/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1674 ms on localhost (5/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1699 ms on localhost (6/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 1674 ms on localhost (7/8)
15/08/15 14:43:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1686 ms on localhost (8/8)
15/08/15 14:43:57 INFO DAGScheduler: ShuffleMapStage 0 (processCmd at CliDriver.java:423) finished in 1.719 s
15/08/15 14:43:57 INFO DAGScheduler: looking for newly runnable stages
15/08/15 14:43:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/08/15 14:43:57 INFO DAGScheduler: running: Set()
15/08/15 14:43:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/08/15 14:43:57 INFO DAGScheduler: failed: Set()
15/08/15 14:43:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/08/15 14:43:57 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at processCmd at CliDriver.java:423), which is now runnable
15/08/15 14:43:57 INFO StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@5a3e4cf8
15/08/15 14:43:57 INFO StatsReportListener: task runtime:(count: 8, mean: 1671.875000, stdev: 13.541026, max: 1699.000000, min: 1659.000000)
15/08/15 14:43:57 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:57 INFO StatsReportListener: 	1.7 s	1.7 s	1.7 s	1.7 s	1.7 s	1.7 s	1.7 s	1.7 s	1.7 s
15/08/15 14:43:57 INFO StatsReportListener: shuffle bytes written:(count: 8, mean: 31.000000, stdev: 0.000000, max: 31.000000, min: 31.000000)
15/08/15 14:43:57 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:57 INFO StatsReportListener: 	31.0 B	31.0 B	31.0 B	31.0 B	31.0 B	31.0 B	31.0 B	31.0 B	31.0 B
15/08/15 14:43:57 INFO StatsReportListener: task result size:(count: 8, mean: 1925.000000, stdev: 0.000000, max: 1925.000000, min: 1925.000000)
15/08/15 14:43:57 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:57 INFO StatsReportListener: 	1925.0 B	1925.0 B	1925.0 B	1925.0 B	1925.0 B	1925.0 B	1925.0 B	1925.0 B	1925.0 B
15/08/15 14:43:58 INFO StatsReportListener: executor (non-fetch) time pct: (count: 8, mean: 90.951981, stdev: 0.767392, max: 91.746988, min: 89.464391)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	89 %	89 %	89 %	91 %	91 %	92 %	92 %	92 %	92 %
15/08/15 14:43:58 INFO StatsReportListener: other time pct: (count: 8, mean: 9.048019, stdev: 0.767392, max: 10.535609, min: 8.253012)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	 8 %	 8 %	 8 %	 8 %	 9 %	10 %	11 %	11 %	11 %
15/08/15 14:43:58 INFO MemoryStore: ensureFreeSpace(80280) called with curMem=295883, maxMem=3333968363
15/08/15 14:43:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 78.4 KB, free 3.1 GB)
15/08/15 14:43:58 INFO MemoryStore: ensureFreeSpace(30693) called with curMem=376163, maxMem=3333968363
15/08/15 14:43:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 30.0 KB, free 3.1 GB)
15/08/15 14:43:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36989 (size: 30.0 KB, free: 3.1 GB)
15/08/15 14:43:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:874
15/08/15 14:43:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at processCmd at CliDriver.java:423)
15/08/15 14:43:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/08/15 14:43:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 8, localhost, PROCESS_LOCAL, 1165 bytes)
15/08/15 14:43:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 8)
15/08/15 14:43:58 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
15/08/15 14:43:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/08/15 14:43:58 INFO DefaultWriterContainer: Using output committer class parquet.hadoop.ParquetOutputCommitter for appending.
15/08/15 14:43:58 INFO ZlibFactory: Successfully loaded & initialized native-zlib library
15/08/15 14:43:58 INFO CodecPool: Got brand-new compressor [.gz]
15/08/15 14:43:58 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 29,150,423
15/08/15 14:43:58 INFO ColumnChunkPageWriteStore: written 75B for [revenue] DOUBLE: 1 values, 14B raw, 34B comp, 1 pages, encodings: [BIT_PACKED, PLAIN, RLE]
15/08/15 14:43:58 INFO FileOutputCommitter: Saved output of task 'attempt_201508151443_0001_m_000000_0' to hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/q6_forecast_revenue_change_par/_temporary/0/task_201508151443_0001_m_000000
15/08/15 14:43:58 INFO SparkHadoopMapRedUtil: attempt_201508151443_0001_m_000000_0: Committed
15/08/15 14:43:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 8). 843 bytes result sent to driver
15/08/15 14:43:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 8) in 505 ms on localhost (1/1)
15/08/15 14:43:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/08/15 14:43:58 INFO DAGScheduler: ResultStage 1 (processCmd at CliDriver.java:423) finished in 0.506 s
15/08/15 14:43:58 INFO StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@4f453018
15/08/15 14:43:58 INFO StatsReportListener: task runtime:(count: 1, mean: 505.000000, stdev: 0.000000, max: 505.000000, min: 505.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	505.0 ms	505.0 ms	505.0 ms	505.0 ms	505.0 ms	505.0 ms	505.0 ms	505.0 ms	505.0 ms
15/08/15 14:43:58 INFO StatsReportListener: fetch wait time:(count: 1, mean: 0.000000, stdev: 0.000000, max: 0.000000, min: 0.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	0.0 ms	0.0 ms	0.0 ms	0.0 ms	0.0 ms	0.0 ms	0.0 ms	0.0 ms	0.0 ms
15/08/15 14:43:58 INFO StatsReportListener: remote bytes read:(count: 1, mean: 0.000000, stdev: 0.000000, max: 0.000000, min: 0.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B
15/08/15 14:43:58 INFO StatsReportListener: task result size:(count: 1, mean: 843.000000, stdev: 0.000000, max: 843.000000, min: 843.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	843.0 B	843.0 B	843.0 B	843.0 B	843.0 B	843.0 B	843.0 B	843.0 B	843.0 B
15/08/15 14:43:58 INFO DAGScheduler: Job 0 finished: processCmd at CliDriver.java:423, took 2.598512 s
15/08/15 14:43:58 INFO StatsReportListener: executor (non-fetch) time pct: (count: 1, mean: 71.089109, stdev: 0.000000, max: 71.089109, min: 71.089109)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	71 %	71 %	71 %	71 %	71 %	71 %	71 %	71 %	71 %
15/08/15 14:43:58 INFO StatsReportListener: fetch wait time pct: (count: 1, mean: 0.000000, stdev: 0.000000, max: 0.000000, min: 0.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	 0 %	 0 %	 0 %	 0 %	 0 %	 0 %	 0 %	 0 %	 0 %
15/08/15 14:43:58 INFO StatsReportListener: other time pct: (count: 1, mean: 28.910891, stdev: 0.000000, max: 28.910891, min: 28.910891)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	29 %	29 %	29 %	29 %	29 %	29 %	29 %	29 %	29 %
15/08/15 14:43:58 INFO ParquetFileReader: Initiating action with parallelism: 5
15/08/15 14:43:58 INFO DefaultWriterContainer: Job job_201508151443_0000 committed.
15/08/15 14:43:58 INFO ParquetFileReader: Initiating action with parallelism: 5
15/08/15 14:43:58 INFO ParquetFileReader: reading summary file: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/q6_forecast_revenue_change_par/_common_metadata
15/08/15 14:43:58 INFO SparkContext: Starting job: processCmd at CliDriver.java:423
15/08/15 14:43:58 INFO DAGScheduler: Got job 1 (processCmd at CliDriver.java:423) with 1 output partitions (allowLocal=false)
15/08/15 14:43:58 INFO DAGScheduler: Final stage: ResultStage 2(processCmd at CliDriver.java:423)
15/08/15 14:43:58 INFO DAGScheduler: Parents of final stage: List()
15/08/15 14:43:58 INFO DAGScheduler: Missing parents: List()
15/08/15 14:43:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at processCmd at CliDriver.java:423), which has no missing parents
15/08/15 14:43:58 INFO MemoryStore: ensureFreeSpace(2848) called with curMem=406856, maxMem=3333968363
15/08/15 14:43:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.8 KB, free 3.1 GB)
15/08/15 14:43:58 INFO MemoryStore: ensureFreeSpace(1717) called with curMem=409704, maxMem=3333968363
15/08/15 14:43:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1717.0 B, free 3.1 GB)
15/08/15 14:43:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:36989 (size: 1717.0 B, free: 3.1 GB)
15/08/15 14:43:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:874
15/08/15 14:43:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at processCmd at CliDriver.java:423)
15/08/15 14:43:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
15/08/15 14:43:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 1316 bytes)
15/08/15 14:43:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 9)
15/08/15 14:43:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 9). 606 bytes result sent to driver
15/08/15 14:43:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 46 ms on localhost (1/1)
15/08/15 14:43:58 INFO DAGScheduler: ResultStage 2 (processCmd at CliDriver.java:423) finished in 0.046 s
15/08/15 14:43:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/08/15 14:43:58 INFO StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@2662d0ad
15/08/15 14:43:58 INFO DAGScheduler: Job 1 finished: processCmd at CliDriver.java:423, took 0.079324 s
15/08/15 14:43:58 INFO StatsReportListener: task runtime:(count: 1, mean: 46.000000, stdev: 0.000000, max: 46.000000, min: 46.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	46.0 ms	46.0 ms	46.0 ms	46.0 ms	46.0 ms	46.0 ms	46.0 ms	46.0 ms	46.0 ms
15/08/15 14:43:58 INFO StatsReportListener: task result size:(count: 1, mean: 606.000000, stdev: 0.000000, max: 606.000000, min: 606.000000)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	606.0 B	606.0 B	606.0 B	606.0 B	606.0 B	606.0 B	606.0 B	606.0 B	606.0 B
15/08/15 14:43:58 INFO StatsReportListener: executor (non-fetch) time pct: (count: 1, mean: 2.173913, stdev: 0.000000, max: 2.173913, min: 2.173913)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %	 2 %
15/08/15 14:43:58 INFO StatsReportListener: other time pct: (count: 1, mean: 97.826087, stdev: 0.000000, max: 97.826087, min: 97.826087)
15/08/15 14:43:58 INFO StatsReportListener: 	0%	5%	10%	25%	50%	75%	90%	95%	100%
15/08/15 14:43:58 INFO StatsReportListener: 	98 %	98 %	98 %	98 %	98 %	98 %	98 %	98 %	98 %
Time taken: 6.523 seconds
15/08/15 14:43:58 INFO CliDriver: Time taken: 6.523 seconds
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/15 14:43:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/08/15 14:43:58 INFO SparkUI: Stopped Spark web UI at http://192.168.122.56:4040
15/08/15 14:43:58 INFO DAGScheduler: Stopping DAGScheduler
15/08/15 14:43:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/08/15 14:43:58 INFO Utils: path = /tmp/spark-19a8e3f3-9eb3-44f3-ae57-a42bb9383c30/blockmgr-9f82bd38-719a-4927-89ee-9df271e40ef9, already present as root for deletion.
15/08/15 14:43:58 INFO MemoryStore: MemoryStore cleared
15/08/15 14:43:58 INFO BlockManager: BlockManager stopped
15/08/15 14:43:58 INFO BlockManagerMaster: BlockManagerMaster stopped
15/08/15 14:43:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/08/15 14:43:58 INFO SparkContext: Successfully stopped SparkContext
15/08/15 14:43:58 INFO Utils: Shutdown hook called
15/08/15 14:43:58 INFO Utils: Deleting directory /tmp/spark-19a8e3f3-9eb3-44f3-ae57-a42bb9383c30
15/08/15 14:43:59 INFO Utils: Deleting directory /tmp/spark-cf69e58f-c827-40e7-b9e1-82d8126ba8ce
15/08/15 14:43:59 INFO Utils: Deleting directory /tmp/spark-b4f175cd-9e35-4e1d-bc48-7d11181b8f9f
15/08/15 14:43:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/08/15 14:43:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/08/15 14:43:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
